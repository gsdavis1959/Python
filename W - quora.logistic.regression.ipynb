{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b2e35a94595b7837b0e297ea70dc3095cd40a9cc"
   },
   "source": [
    "This kernel focuses on solutions that don't use embeddings. The idea is that you can get an F1 score of ~0.66 in a short amount of time (15 minutes?) That should leave enough time for a deep learning model or two and some ensembling before the kernel times out. \n",
    "\n",
    "## Quick Intro to Quora\n",
    "Quora is one of my favorite sites to visit. You can learn about useful things and also totally useless things. Of coures this is quite different than our objective here, which is to say whether or not a question is sincere. Here's an example - sounds sincere, but is it useful? Not to me since I don't interact with anteaters. I appreciate it just the same and love Quora for these types of questions!\n",
    "\n",
    "![anteater](https://s4.scoopwhoop.com/anj/cashkaro/27222808.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ce28218cc04f8573728074cc21a7dba6f8438f86"
   },
   "source": [
    "Back to the task at hand. From the Data tab of the competition, we have some explanation of what is insincere.\n",
    " \n",
    "> An insincere question is defined as a question intended to make a statement rather than look for helpful answers. Some characteristics that can signify that a question is insincere:\n",
    "> \n",
    "> * Has a non-neutral tone\n",
    "> * Is disparaging or inflammatory\n",
    "> * Isn't grounded in reality\n",
    "> * Uses sexual content for shock value, and not to seek genuine answers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "68af29d8294a5587d57186c2c0d98a8174f94d15"
   },
   "source": [
    "## The Model(s)\n",
    "I'm basing the model on good techniques seen in other competitions and this one. F1_score and execution speed are my main criteria. For now I use cross-validation even though it takes a lot of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "67f213049362781a00f6d77cdc960d129cbc506b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['embeddings', 'sample_submission.csv', 'test.csv', 'train.csv']\n",
      "tokenizing\n",
      "Wall time: 1min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#%% get libraries and data\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "import os\n",
    "os.chdir (\"C:\\\\Users\\gsdav\\Documents\\Data\\Datasets\\quora\")\n",
    "print(os.listdir())# Read in the dataframes\n",
    "\n",
    "numrows = None\n",
    "train = pd.read_csv('train.csv', index_col=['qid'], nrows=numrows)\n",
    "test = pd.read_csv('test.csv', index_col=['qid'], nrows=numrows)\n",
    "y = train.target.values\n",
    "\n",
    "#%% make word vectors - todo:catch numbers and punctuation, find faster tokenizer (NTLK, Spacy?)\n",
    "word_vectorizer = TfidfVectorizer(ngram_range=(1,2),\n",
    "                                    min_df=3,\n",
    "                                    max_df=0.9,\n",
    "                                    token_pattern=r'\\w{1,}',\n",
    "                                    stop_words='english',\n",
    "                                    max_features=50_000,\n",
    "                                    strip_accents='unicode',\n",
    "                                    use_idf=True,\n",
    "                                    smooth_idf=True,\n",
    "                                    sublinear_tf=True)\n",
    "\n",
    "print(\"tokenizing\")\n",
    "word_vectorizer.fit(pd.concat((train['question_text'], test['question_text'])))\n",
    "X = word_vectorizer.transform(train['question_text'])\n",
    "X_test = word_vectorizer.transform(test['question_text'])\n",
    "\n",
    "#%% make character vectors - coming soon\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "094f7e6d02b3588a5ce0f5e7e478a711c2a87de9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb transforming\n",
      "Wall time: 685 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#%% Transform with Naive Bayes - combo of Ren and Jeremy Howard\n",
    "class NBTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, alpha=1):\n",
    "        self.r = None\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        p = self.alpha + X[y==1].sum(0)\n",
    "        q = self.alpha + X[y==0].sum(0)\n",
    "        self.r = csr_matrix(np.log(\n",
    "            (p / (self.alpha + (y==1).sum())) /\n",
    "            (q / (self.alpha + (y==0).sum()))\n",
    "        ))\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X.multiply(self.r)\n",
    "\n",
    "print(\"nb transforming\")\n",
    "nbt = NBTransformer(alpha=1)\n",
    "nbt.fit(X, y)\n",
    "X_nb = nbt.transform(X)\n",
    "X_test_nb = nbt.transform(X_test)\n",
    "np.unique(X_nb.getrow(1).toarray()) #look at some contents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_kg_hide-output": true,
    "_uuid": "a42e90e2af24688b40b65f9ee69e158ef25aeedb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 49 epochs took 38 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   37.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 47 epochs took 37 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   37.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 47 epochs took 36 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   36.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 50 epochs took 39 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   39.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 45 epochs took 35 seconds\n",
      "Wall time: 3min 8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   34.9s finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#%% make splits for reuse\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=911)\n",
    "splits = list(skf.split(train, y))\n",
    "\n",
    "# Logistic Regression\n",
    "train_pred = np.zeros(train.shape[0])\n",
    "test_pred = np.zeros(X_test.shape[0])\n",
    "for train_idx, val_idx in splits:\n",
    "    X_train, y_train  = X_nb[train_idx], y[train_idx]\n",
    "    X_val, y_val = X_nb[val_idx], y[val_idx]\n",
    "    model = LogisticRegression(solver='saga', class_weight='balanced', \n",
    "                                    C=0.5, max_iter=250, verbose=1) #seed not set\n",
    "    model.fit(X_train, y_train)\n",
    "    val_pred = model.predict_proba(X_val)\n",
    "    train_pred[val_idx] = val_pred[:,1]\n",
    "    test_pred += model.predict_proba(X_test_nb)[:,1] / skf.get_n_splits()\n",
    "    \n",
    "# Topic Modeling? - coming soon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_kg_hide-output": false,
    "_uuid": "0a6eef8c1bf9395fa70e0dde1b7520692fe807a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9513583548477741\n",
      "0.8300000000000001 0.6066648162728916\n",
      "Wall time: 26.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#%% find best threshold\n",
    "def thresh_search(y_true, y_proba):\n",
    "    best_thresh = 0\n",
    "    best_score = 0\n",
    "    for thresh in np.arange(0, 1, 0.01):\n",
    "        score = f1_score(y_true, y_proba > thresh)\n",
    "        if score > best_score:\n",
    "            best_thresh = thresh\n",
    "            best_score = score\n",
    "    return best_thresh, best_score\n",
    "\n",
    "print(roc_auc_score(y, train_pred))\n",
    "thresh, score = thresh_search(y, train_pred)\n",
    "print(thresh, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "556943a36261fc69e42a7724931839a7a30dc6c6"
   },
   "outputs": [],
   "source": [
    "# submit\n",
    "sub = pd.read_csv('sample_submission.csv', index_col=['qid'], nrows=numrows)\n",
    "sub['prediction'] = test_pred > thresh\n",
    "sub.to_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "881f4d8d0659fe5494c7cfee80495de95743c22e"
   },
   "source": [
    "All for now - stay tuned!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
