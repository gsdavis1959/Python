{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KnowledgeGraph.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "waxxtEC4YvSi",
        "outputId": "b7b1caa5-f83e-4085-80da-6f5da0076426"
      },
      "source": [
        "!pip install wikipedia-api\n",
        "!pip install neuralcoref\n",
        "!pip install spacy\n",
        "!pip install en_core_web_lg"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wikipedia-api in /usr/local/lib/python3.7/dist-packages (0.5.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from wikipedia-api) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->wikipedia-api) (1.25.11)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->wikipedia-api) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->wikipedia-api) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->wikipedia-api) (2.10)\n",
            "Requirement already satisfied: neuralcoref in /usr/local/lib/python3.7/dist-packages (4.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from neuralcoref) (2.23.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from neuralcoref) (1.18.40)\n",
            "Requirement already satisfied: spacy>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from neuralcoref) (2.2.4)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from neuralcoref) (1.19.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (1.25.11)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (2021.5.30)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.0->neuralcoref) (0.8.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.0->neuralcoref) (7.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.0->neuralcoref) (1.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.0->neuralcoref) (4.62.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.0->neuralcoref) (1.1.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.0->neuralcoref) (1.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.0->neuralcoref) (1.0.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.0->neuralcoref) (2.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.0->neuralcoref) (57.4.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.0->neuralcoref) (3.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.0->neuralcoref) (0.4.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.1.0->neuralcoref) (4.6.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.1.0->neuralcoref) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.1.0->neuralcoref) (3.7.4.3)\n",
            "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from boto3->neuralcoref) (0.5.0)\n",
            "Requirement already satisfied: botocore<1.22.0,>=1.21.40 in /usr/local/lib/python3.7/dist-packages (from boto3->neuralcoref) (1.21.40)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->neuralcoref) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.22.0,>=1.21.40->boto3->neuralcoref) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.22.0,>=1.21.40->boto3->neuralcoref) (1.15.0)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (2.2.4)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.62.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.19.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (4.6.4)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy) (3.5.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.25.11)\n",
            "Requirement already satisfied: en_core_web_lg in /usr/local/lib/python3.7/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_lg) (2.2.4)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg) (7.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg) (0.8.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg) (1.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg) (4.62.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg) (1.19.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg) (1.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg) (57.4.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg) (3.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg) (1.1.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg) (2.0.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg) (1.0.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg) (4.6.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg) (3.7.4.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg) (1.25.11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQbiSzvAY7JT"
      },
      "source": [
        "import wikipediaapi  # pip install wikipedia-api\n",
        "import pandas as pd\n",
        "import concurrent.futures\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Jy3BeY9ZDNZ"
      },
      "source": [
        "def wiki_scrape(topic_name, verbose=True):\n",
        "    def wiki_link(link):\n",
        "        try:\n",
        "            page = wiki_api.page(link)\n",
        "            if page.exists():\n",
        "                return {'page': link, 'text': page.text, 'link': page.fullurl,\n",
        "                        'categories': list(page.categories.keys())}\n",
        "        except:\n",
        "            return None\n",
        "\n",
        "    wiki_api = wikipediaapi.Wikipedia(language='en',\n",
        "        extract_format=wikipediaapi.ExtractFormat.WIKI)\n",
        "    page_name = wiki_api.page(topic_name)\n",
        "    if not page_name.exists():\n",
        "        print('Page {} does not exist.'.format(topic_name))\n",
        "        return\n",
        "    \n",
        "    page_links = list(page_name.links.keys())\n",
        "    progress = tqdm(desc='Links Scraped', unit='', total=len(page_links)) if verbose else None\n",
        "    sources = [{'page': topic_name, 'text': page_name.text, 'link': page_name.fullurl,\n",
        "                'categories': list(page_name.categories.keys())}]\n",
        "    \n",
        "    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n",
        "        future_link = {executor.submit(wiki_link, link): link for link in page_links}\n",
        "        for future in concurrent.futures.as_completed(future_link):\n",
        "            data = future.result()\n",
        "            sources.append(data) if data else None\n",
        "            progress.update(1) if verbose else None     \n",
        "    progress.close() if verbose else None\n",
        "    \n",
        "    namespaces = ('Wikipedia', 'Special', 'Talk', 'LyricWiki', 'File', 'MediaWiki',\n",
        "                  'Template', 'Help', 'User', 'Category talk', 'Portal talk')\n",
        "    sources = pd.DataFrame(sources)\n",
        "    sources = sources[(len(sources['text']) > 20)\n",
        "                      & ~(sources['page'].str.startswith(namespaces, na=True))]\n",
        "    sources['categories'] = sources.categories.apply(lambda x: [y[9:] for y in x])\n",
        "    sources['topic'] = topic_name\n",
        "    print('Wikipedia pages scraped:', len(sources))\n",
        "    \n",
        "    return sources"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKRsHE3qZL6O",
        "outputId": "648a0c55-812e-436d-9756-0bdca545171f"
      },
      "source": [
        "wiki_data = wiki_scrape('Financial crisis of 2007–08')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Links Scraped: 100%|██████████| 1023/1023 [01:17<00:00, 13.15/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wikipedia pages scraped: 1006\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "kZ7JW0jKZ80j",
        "outputId": "a546dbc1-64a7-4cb7-dff6-524023c7f136"
      },
      "source": [
        "wiki_data.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>page</th>\n",
              "      <th>text</th>\n",
              "      <th>link</th>\n",
              "      <th>categories</th>\n",
              "      <th>topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Financial crisis of 2007–08</td>\n",
              "      <td>The financial crisis of 2007–2008, also known ...</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Financial_crisis...</td>\n",
              "      <td>[2000s economic history, 2007 in economics, 20...</td>\n",
              "      <td>Financial crisis of 2007–08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1970s energy crisis</td>\n",
              "      <td>The 1970s energy crisis occurred when the West...</td>\n",
              "      <td>https://en.wikipedia.org/wiki/1970s_energy_crisis</td>\n",
              "      <td>[1970s economic history, 1979 in economics, Al...</td>\n",
              "      <td>Financial crisis of 2007–08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1973–1974 stock market crash</td>\n",
              "      <td>The 1973–1974 stock market crash caused a bear...</td>\n",
              "      <td>https://en.wikipedia.org/wiki/1973%E2%80%93197...</td>\n",
              "      <td>[1973 in economics, 1974 in economics, All art...</td>\n",
              "      <td>Financial crisis of 2007–08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1973–1975 recession</td>\n",
              "      <td>The 1973–1975 recession or 1970s recession was...</td>\n",
              "      <td>https://en.wikipedia.org/wiki/1973%E2%80%93197...</td>\n",
              "      <td>[1970s economic history, 1973 in economics, 19...</td>\n",
              "      <td>Financial crisis of 2007–08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1933 Banking Act</td>\n",
              "      <td>The Banking Act of 1933 (Pub.L. 73–66, 48 Stat...</td>\n",
              "      <td>https://en.wikipedia.org/wiki/1933_Banking_Act</td>\n",
              "      <td>[1933 in American law, 1933 in economics, 73rd...</td>\n",
              "      <td>Financial crisis of 2007–08</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           page  ...                        topic\n",
              "0   Financial crisis of 2007–08  ...  Financial crisis of 2007–08\n",
              "1           1970s energy crisis  ...  Financial crisis of 2007–08\n",
              "2  1973–1974 stock market crash  ...  Financial crisis of 2007–08\n",
              "3           1973–1975 recession  ...  Financial crisis of 2007–08\n",
              "4              1933 Banking Act  ...  Financial crisis of 2007–08\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eorcR5GRZalQ"
      },
      "source": [
        "# single page\n",
        "def wiki_page(page_name):\n",
        "    wiki_api = wikipediaapi.Wikipedia(language='en',\n",
        "            extract_format=wikipediaapi.ExtractFormat.WIKI)\n",
        "    page_name = wiki_api.page(page_name)\n",
        "    if not page_name.exists():\n",
        "        print('Page {} does not exist.'.format(page_name))\n",
        "        return\n",
        "\n",
        "    page_data = pd.DataFrame({\n",
        "        'page': page_name,\n",
        "        'text': page_name.text,\n",
        "        'link': page_name.fullurl,\n",
        "        'categories': [[y[9:] for y in\n",
        "                       list(page_name.categories.keys())]],\n",
        "        })\n",
        "\n",
        "    return page_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPeGYOPMZdqN",
        "outputId": "abe611d5-f436-4f1a-8df6-0d6bf5c5a96b"
      },
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import spacy\n",
        "import neuralcoref\n",
        "#!python -m spacy download en_core_web_lg\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: spacy.morphology.Morphology size changed, may indicate binary incompatibility. Expected 104 from C header, got 112 from PyObject\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: spacy.vocab.Vocab size changed, may indicate binary incompatibility. Expected 96 from C header, got 104 from PyObject\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: spacy.tokens.span.Span size changed, may indicate binary incompatibility. Expected 72 from C header, got 80 from PyObject\n",
            "  return f(*args, **kwds)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bq7huR_b-Xl"
      },
      "source": [
        "import en_core_web_lg\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "niI8DDx8cgge",
        "outputId": "5b63d65e-cf48-4538-98f3-e646c37e4817"
      },
      "source": [
        "nlp = en_core_web_lg.load()\n",
        "neuralcoref.add_to_pipe(nlp)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<spacy.lang.en.English at 0x7feee9b51150>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08eBftsdZmDV"
      },
      "source": [
        "def get_entity_pairs(text, coref=True):\n",
        "    # preprocess text\n",
        "    text = re.sub(r'\\n+', '.', text)  # replace multiple newlines with period\n",
        "    text = re.sub(r'\\[\\d+\\]', ' ', text)  # remove reference numbers\n",
        "    text = nlp(text)\n",
        "    if coref:\n",
        "        text = nlp(text._.coref_resolved)  # resolve coreference clusters\n",
        "\n",
        "    def refine_ent(ent, sent):\n",
        "        unwanted_tokens = (\n",
        "            'PRON',  # pronouns\n",
        "            'PART',  # particle\n",
        "            'DET',  # determiner\n",
        "            'SCONJ',  # subordinating conjunction\n",
        "            'PUNCT',  # punctuation\n",
        "            'SYM',  # symbol\n",
        "            'X',  # other\n",
        "        )\n",
        "        ent_type = ent.ent_type_  # get entity type\n",
        "        if ent_type == '':\n",
        "            ent_type = 'NOUN_CHUNK'\n",
        "            ent = ' '.join(str(t.text) for t in\n",
        "                           nlp(str(ent)) if t.pos_\n",
        "                           not in unwanted_tokens and t.is_stop == False)\n",
        "        elif ent_type in ('NOMINAL', 'CARDINAL', 'ORDINAL') and str(ent).find(' ') == -1:\n",
        "            refined = ''\n",
        "            for i in range(len(sent) - ent.i):\n",
        "                if ent.nbor(i).pos_ not in ('VERB', 'PUNCT'):\n",
        "                    refined += ' ' + str(ent.nbor(i))\n",
        "                else:\n",
        "                    ent = refined.strip()\n",
        "                    break\n",
        "\n",
        "        return ent, ent_type\n",
        "\n",
        "    sentences = [sent.string.strip() for sent in text.sents]  # split text into sentences\n",
        "    ent_pairs = []\n",
        "    for sent in sentences:\n",
        "        sent = nlp(sent)\n",
        "        spans = list(sent.ents) + list(sent.noun_chunks)  # collect nodes\n",
        "        spans = spacy.util.filter_spans(spans)\n",
        "        with sent.retokenize() as retokenizer:\n",
        "            [retokenizer.merge(span, attrs={'tag': span.root.tag,\n",
        "                                            'dep': span.root.dep}) for span in spans]\n",
        "        deps = [token.dep_ for token in sent]\n",
        "\n",
        "        # limit our example to simple sentences with one subject and object\n",
        "        if (deps.count('obj') + deps.count('dobj')) != 1\\\n",
        "                or (deps.count('subj') + deps.count('nsubj')) != 1:\n",
        "            continue\n",
        "\n",
        "        for token in sent:\n",
        "            if token.dep_ not in ('obj', 'dobj'):  # identify object nodes\n",
        "                continue\n",
        "            subject = [w for w in token.head.lefts if w.dep_\n",
        "                       in ('subj', 'nsubj')]  # identify subject nodes\n",
        "            if subject:\n",
        "                subject = subject[0]\n",
        "                # identify relationship by root dependency\n",
        "                relation = [w for w in token.ancestors if w.dep_ == 'ROOT']\n",
        "                if relation:\n",
        "                    relation = relation[0]\n",
        "                    # add adposition or particle to relationship\n",
        "                    if relation.nbor(1).pos_ in ('ADP', 'PART'):\n",
        "                        relation = ' '.join((str(relation), str(relation.nbor(1))))\n",
        "                else:\n",
        "                    relation = 'unknown'\n",
        "\n",
        "                subject, subject_type = refine_ent(subject, sent)\n",
        "                token, object_type = refine_ent(token, sent)\n",
        "\n",
        "                ent_pairs.append([str(subject), str(relation), str(token),\n",
        "                                  str(subject_type), str(object_type)])\n",
        "\n",
        "    ent_pairs = [sublist for sublist in ent_pairs\n",
        "                          if not any(str(ent) == '' for ent in sublist)]\n",
        "    pairs = pd.DataFrame(ent_pairs, columns=['subject', 'relation', 'object',\n",
        "                                             'subject_type', 'object_type'])\n",
        "    print('Entity pairs extracted:', str(len(ent_pairs)))\n",
        "\n",
        "    return pairs"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsuIDdxPdE3S"
      },
      "source": [
        "pairs = get_entity_pairs(wiki_data.loc[0,'text'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dhu9t0e2e2KS"
      },
      "source": [
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def draw_kg(pairs):\n",
        "    k_graph = nx.from_pandas_edgelist(pairs, 'subject', 'object',\n",
        "            create_using=nx.MultiDiGraph())\n",
        "    node_deg = nx.degree(k_graph)\n",
        "    layout = nx.spring_layout(k_graph, k=0.15, iterations=20)\n",
        "    plt.figure(num=None, figsize=(120, 90), dpi=80)\n",
        "    nx.draw_networkx(\n",
        "        k_graph,\n",
        "        node_size=[int(deg[1]) * 500 for deg in node_deg],\n",
        "        arrowsize=20,\n",
        "        linewidths=1.5,\n",
        "        pos=layout,\n",
        "        edge_color='red',\n",
        "        edgecolors='black',\n",
        "        node_color='white',\n",
        "        )\n",
        "    labels = dict(zip(list(zip(pairs.subject, pairs.object)),\n",
        "                  pairs['relation'].tolist()))\n",
        "    nx.draw_networkx_edge_labels(k_graph, pos=layout, edge_labels=labels,\n",
        "                                 font_color='red')\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLmR-eLHfBIu"
      },
      "source": [
        "draw_kg(pairs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nb_QUbnwfBjU"
      },
      "source": [
        "def filter_graph(pairs, node):\n",
        "    k_graph = nx.from_pandas_edgelist(pairs, 'subject', 'object',\n",
        "            create_using=nx.MultiDiGraph())\n",
        "    edges = nx.dfs_successors(k_graph, node)\n",
        "    nodes = []\n",
        "    for k, v in edges.items():\n",
        "        nodes.extend([k])\n",
        "        nodes.extend(v)\n",
        "    subgraph = k_graph.subgraph(nodes)\n",
        "    layout = (nx.random_layout(k_graph))\n",
        "    nx.draw_networkx(\n",
        "        subgraph,\n",
        "        node_size=1000,\n",
        "        arrowsize=20,\n",
        "        linewidths=1.5,\n",
        "        pos=layout,\n",
        "        edge_color='red',\n",
        "        edgecolors='black',\n",
        "        node_color='white'\n",
        "        )\n",
        "    labels = dict(zip((list(zip(pairs.subject, pairs.object))),\n",
        "                    pairs['relation'].tolist()))\n",
        "    edges= tuple(subgraph.out_edges(data=False))\n",
        "    sublabels ={k: labels[k] for k in edges}\n",
        "    nx.draw_networkx_edge_labels(subgraph, pos=layout, edge_labels=sublabels,\n",
        "                                font_color='red')\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ANpyS_ofJAa"
      },
      "source": [
        "filter_graph(pairs, 'Congress')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}