{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "text = \"The first time you see The Second Renaissance it may look boring. Look at it at least twice and definitely watch part 2. It will change your view of the matrix. Are the human people the ones who started the war ? Is AI a bad thing ?\"\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1aQRIxzR6jJ",
        "outputId": "e439b03f-cc6e-4ebb-cf99-92c054a4a125"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The first time you see The Second Renaissance it may look boring. Look at it at least twice and definitely watch part 2. It will change your view of the matrix. Are the human people the ones who started the war ? Is AI a bad thing ?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to lowercase\n",
        "text = text.lower()\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tLSM1_bSlld",
        "outputId": "ab3219e8-71cc-44b9-8c06-a730c93e2a64"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the first time you see the second renaissance it may look boring. look at it at least twice and definitely watch part 2. it will change your view of the matrix. are the human people the ones who started the war ? is ai a bad thing ?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove punctuation characters\n",
        "import re\n",
        "text = re.sub(r\"[^a-zA-Z0-9]\",\" \",text)\n",
        "text = re.sub(r\"^\\d+\\s|\\s\\d+\\s|\\s\\d+$\", \"\", text)\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-27slbR1SrZG",
        "outputId": "1ac8e234-602e-4266-a419-d35b3202599e"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the first time you see the second renaissance it may look boring  look at it at least twice and definitely watch part it will change your view of the matrix  are the human people the ones who started the war   is ai a bad thing  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgGz-T2tSv6-",
        "outputId": "319f81cb-148a-4831-c026-f11d8c8f2e64"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import statements\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import sent_tokenize"
      ],
      "metadata": {
        "id": "zrrXa35oS1dN"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split text into words using NLTK\n",
        "words = word_tokenize(text)\n",
        "print(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tRW_qhES9Fu",
        "outputId": "dfa6b993-cb70-4a71-b32f-3d6487627b97"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['the', 'first', 'time', 'you', 'see', 'the', 'second', 'renaissance', 'it', 'may', 'look', 'boring', 'look', 'at', 'it', 'at', 'least', 'twice', 'and', 'definitely', 'watch', 'part', 'it', 'will', 'change', 'your', 'view', 'of', 'the', 'matrix', 'are', 'the', 'human', 'people', 'the', 'ones', 'who', 'started', 'the', 'war', 'is', 'ai', 'a', 'bad', 'thing']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split text into sentences using NLTK\n",
        "words = sent_tokenize(text)\n",
        "print(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjwmYn2vTC3z",
        "outputId": "73660391-4e8b-49a8-eb45-d698d48b04b4"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['the first time you see the second renaissance it may look boring  look at it at least twice and definitely watch part it will change your view of the matrix  are the human people the ones who started the war   is ai a bad thing']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIuJTjDxTI2J",
        "outputId": "29d194f2-59e5-4c3d-d4ed-9d248456fa24"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import statements\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "SmJxHY9HTNcc"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove stop wors\n",
        "words = [w for w in words if w not in stopwords.words(\"english\")]\n",
        "print(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfYDmmzmTR2s",
        "outputId": "f83d93ab-1708-443b-95e2-a08062ba2348"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['the first time you see the second renaissance it may look boring  look at it at least twice and definitely watch part it will change your view of the matrix  are the human people the ones who started the war   is ai a bad thing']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(stopwords.words(\"english\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41k_OT81TanJ",
        "outputId": "080e0bb4-62b4-4f98-94d0-bc023530048f"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('words')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJYjwNvqThBV",
        "outputId": "8b0eef9c-2382-4e03-8074-7f3ef6eaedc4"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  import statements\n",
        "from nltk import pos_tag\n",
        "from nltk import ne_chunk"
      ],
      "metadata": {
        "id": "pWK5vAELTmXG"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize text\n",
        "sentence = word_tokenize(text)\n",
        "# tag each word with part of speech\n",
        "pos_tag(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAhGfof0TrDu",
        "outputId": "ef20ba2b-fde9-4811-ce58-38d4f2d7ce47"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 'DT'),\n",
              " ('first', 'JJ'),\n",
              " ('time', 'NN'),\n",
              " ('you', 'PRP'),\n",
              " ('see', 'VBP'),\n",
              " ('the', 'DT'),\n",
              " ('second', 'JJ'),\n",
              " ('renaissance', 'NN'),\n",
              " ('it', 'PRP'),\n",
              " ('may', 'MD'),\n",
              " ('look', 'VB'),\n",
              " ('boring', 'JJ'),\n",
              " ('look', 'NN'),\n",
              " ('at', 'IN'),\n",
              " ('it', 'PRP'),\n",
              " ('at', 'IN'),\n",
              " ('least', 'JJS'),\n",
              " ('twice', 'RB'),\n",
              " ('and', 'CC'),\n",
              " ('definitely', 'RB'),\n",
              " ('watch', 'VB'),\n",
              " ('part', 'NN'),\n",
              " ('it', 'PRP'),\n",
              " ('will', 'MD'),\n",
              " ('change', 'VB'),\n",
              " ('your', 'PRP$'),\n",
              " ('view', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('matrix', 'NN'),\n",
              " ('are', 'VBP'),\n",
              " ('the', 'DT'),\n",
              " ('human', 'JJ'),\n",
              " ('people', 'NNS'),\n",
              " ('the', 'DT'),\n",
              " ('ones', 'NNS'),\n",
              " ('who', 'WP'),\n",
              " ('started', 'VBD'),\n",
              " ('the', 'DT'),\n",
              " ('war', 'NN'),\n",
              " ('is', 'VBZ'),\n",
              " ('ai', 'RP'),\n",
              " ('a', 'DT'),\n",
              " ('bad', 'JJ'),\n",
              " ('thing', 'NN')]"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize, pos tag, then recognize named entities in text\n",
        "tree = ne_chunk(pos_tag(word_tokenize(text)))\n",
        "print(tree)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RNpn4ECT9DR",
        "outputId": "807fe7da-1540-419e-9ee8-1e6a1cd194ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  the/DT\n",
            "  first/JJ\n",
            "  time/NN\n",
            "  you/PRP\n",
            "  see/VBP\n",
            "  the/DT\n",
            "  second/JJ\n",
            "  renaissance/NN\n",
            "  it/PRP\n",
            "  may/MD\n",
            "  look/VB\n",
            "  boring/JJ\n",
            "  look/NN\n",
            "  at/IN\n",
            "  it/PRP\n",
            "  at/IN\n",
            "  least/JJS\n",
            "  twice/RB\n",
            "  and/CC\n",
            "  definitely/RB\n",
            "  watch/VB\n",
            "  part/NN\n",
            "  2/CD\n",
            "  it/PRP\n",
            "  will/MD\n",
            "  change/VB\n",
            "  your/PRP$\n",
            "  view/NN\n",
            "  of/IN\n",
            "  the/DT\n",
            "  matrix/NN\n",
            "  are/VBP\n",
            "  the/DT\n",
            "  human/JJ\n",
            "  people/NNS\n",
            "  the/DT\n",
            "  ones/NNS\n",
            "  who/WP\n",
            "  started/VBD\n",
            "  the/DT\n",
            "  war/NN\n",
            "  is/VBZ\n",
            "  ai/RP\n",
            "  a/DT\n",
            "  bad/JJ\n",
            "  thing/NN)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a custom grammar that includes the missing words\n",
        "my_grammar = nltk.CFG.fromstring(\"\"\"\n",
        "  S -> NP VP\n",
        "  PP -> P NP\n",
        "  NP -> Det N | Det N PP | 'I' | 'you' | 'it' | Det ADJ N | N\n",
        "  VP -> V NP | VP PP | V | V ADJ | V N | V Det N\n",
        "  Det -> 'an' | 'my' | 'the' | 'your' | 'a' | '2'\n",
        "  N -> 'elephant' | 'pajamas' | 'time' | 'renaissance' | 'part' | 'view' | 'matrix' | 'people' | 'ones' |'war' | 'thing' | 'first' | 'second' | 'human' | 'ai'\n",
        "  V -> 'shot' | 'see' | 'look' | 'watch' | 'change' | 'started' | 'is' | 'may' | 'are' | 'will'\n",
        "  ADJ -> 'boring' | 'bad' | 'least' | 'twice' | 'watch' | 'change' | 'started' | 'definitely'\n",
        "  P -> 'in' | 'at' | 'of' | 'who' | 'and'\n",
        "  \"\"\")\n",
        "# The code above adds all the missing words to the grammar.\n",
        "# Some rules have been updated to reflect relationships between the new words.\n",
        "# For example, 'your' has been added to Det and 'human' and 'ai' have been added to N.\n",
        "# You may need to further refine these rules and add new rules to improve the parsing accuracy.\n",
        "\n",
        "\n",
        "parser = nltk.ChartParser(my_grammar)\n",
        "\n",
        "for tree in parser.parse(sentence):\n",
        "  print(tree)"
      ],
      "metadata": {
        "id": "8rfrzU1XUCi2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for tree in parser.parse(sentence):\n",
        "    print(tree)"
      ],
      "metadata": {
        "id": "H98J1Ns7UJb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet') # download for lemmatization"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gInOtXucVp6q",
        "outputId": "e93669df-bb18-4285-d28f-58db37325f00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"The first time you see The Second Renaissance it may look boring. Look at it at least twice and definitely watch part 2. It will change your view of the matrix. Are the human people the ones who started the war ? Is AI a bad thing ?\"\n",
        "\n",
        "# Normalize text\n",
        "text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text.lower())\n",
        "\n",
        "# Tokenize text\n",
        "words = text.split()\n",
        "print(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKQi_I3hV7jn",
        "outputId": "b47690f1-4ea4-4fe6-db12-1a45e1daaebc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['the', 'first', 'time', 'you', 'see', 'the', 'second', 'renaissance', 'it', 'may', 'look', 'boring', 'look', 'at', 'it', 'at', 'least', 'twice', 'and', 'definitely', 'watch', 'part', '2', 'it', 'will', 'change', 'your', 'view', 'of', 'the', 'matrix', 'are', 'the', 'human', 'people', 'the', 'ones', 'who', 'started', 'the', 'war', 'is', 'ai', 'a', 'bad', 'thing']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove stop words\n",
        "words = [w for w in words if w not in stopwords.words(\"english\")]\n",
        "print(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqNA5_YGV_9o",
        "outputId": "6bf1310b-e980-4ac9-a394-91673ff25529"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['first', 'time', 'see', 'second', 'renaissance', 'may', 'look', 'boring', 'look', 'least', 'twice', 'definitely', 'watch', 'part', '2', 'change', 'view', 'matrix', 'human', 'people', 'ones', 'started', 'war', 'ai', 'bad', 'thing']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "# Reduce words to their stems\n",
        "stemmed = [PorterStemmer().stem(w) for w in words]\n",
        "print(stemmed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGEndDBkWEFj",
        "outputId": "5ed35221-de15-45bb-ad97-d99942e87102"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['first', 'time', 'see', 'second', 'renaiss', 'may', 'look', 'bore', 'look', 'least', 'twice', 'definit', 'watch', 'part', '2', 'chang', 'view', 'matrix', 'human', 'peopl', 'one', 'start', 'war', 'ai', 'bad', 'thing']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "\n",
        "# Reduce words to their root form\n",
        "lemmed = [WordNetLemmatizer().lemmatize(w) for w in words]\n",
        "print(lemmed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yD9wqIGGWIau",
        "outputId": "89e4a624-f57a-46ad-f6d9-6c252fb4e468"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['first', 'time', 'see', 'second', 'renaissance', 'may', 'look', 'boring', 'look', 'least', 'twice', 'definitely', 'watch', 'part', '2', 'change', 'view', 'matrix', 'human', 'people', 'one', 'started', 'war', 'ai', 'bad', 'thing']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lemmatize verbs by specifying pos\n",
        "lemmed = [WordNetLemmatizer().lemmatize(w, pos='v') for w in lemmed]\n",
        "print(lemmed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6W5ddXBWNH9",
        "outputId": "b87b6641-ddc4-4514-c40f-ac0b1e1cf855"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['first', 'time', 'see', 'second', 'renaissance', 'may', 'look', 'bore', 'look', 'least', 'twice', 'definitely', 'watch', 'part', '2', 'change', 'view', 'matrix', 'human', 'people', 'one', 'start', 'war', 'ai', 'bad', 'thing']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = [\"The first time you see The Second Renaissance it may look boring.\",\n",
        "        \"Look at it at least twice and definitely watch part 2.\",\n",
        "        \"It will change your view of the matrix.\",\n",
        "        \"Are the human people the ones who started the war?\",\n",
        "        \"Is AI a bad thing ?\"]"
      ],
      "metadata": {
        "id": "NPQ5Ej7UWSw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = stopwords.words(\"english\")\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "UDaV70FfWZz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(text):\n",
        "    # normalize case and remove punctuation\n",
        "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text.lower())\n",
        "\n",
        "    # tokenize text\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # lemmatize andremove stop words\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
        "\n",
        "    return tokens"
      ],
      "metadata": {
        "id": "Zd2jGL7aWeQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# initialize count vectorizer object\n",
        "vect = CountVectorizer(tokenizer=tokenize)"
      ],
      "metadata": {
        "id": "ft_XRt4wWicA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get counts of each token (word) in text data\n",
        "X = vect.fit_transform(corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qruksod0WoDR",
        "outputId": "5d9de6b2-c1ee-471a-bc63-cb1087518883"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert sparse matrix to numpy array to view\n",
        "X.toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bW86e7X6WsSi",
        "outputId": "015411f9-4eb8-48ca-9ea0-a745faa1c257"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0,\n",
              "        0, 0, 0],\n",
              "       [1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "        0, 0, 1],\n",
              "       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        1, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
              "        0, 1, 0],\n",
              "       [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "        0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# view token vocabulary and counts\n",
        "vect.vocabulary_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5sUfdoaWwCl",
        "outputId": "86449356-80a3-4ee5-c433-1d2137186b90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'first': 6,\n",
              " 'time': 20,\n",
              " 'see': 17,\n",
              " 'second': 16,\n",
              " 'renaissance': 15,\n",
              " 'may': 11,\n",
              " 'look': 9,\n",
              " 'boring': 3,\n",
              " 'least': 8,\n",
              " 'twice': 21,\n",
              " 'definitely': 5,\n",
              " 'watch': 24,\n",
              " 'part': 13,\n",
              " '2': 0,\n",
              " 'change': 4,\n",
              " 'view': 22,\n",
              " 'matrix': 10,\n",
              " 'human': 7,\n",
              " 'people': 14,\n",
              " 'one': 12,\n",
              " 'started': 18,\n",
              " 'war': 23,\n",
              " 'ai': 1,\n",
              " 'bad': 2,\n",
              " 'thing': 19}"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "# initialize tf-idf transformer object\n",
        "transformer = TfidfTransformer(smooth_idf=False)"
      ],
      "metadata": {
        "id": "ygUF7oJHW1YA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use counts from count vectorizer results to compute tf-idf values\n",
        "tfidf = transformer.fit_transform(X)"
      ],
      "metadata": {
        "id": "A2JXE6_-W5NB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert sparse matrix to numpy array to view\n",
        "tfidf.toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B94idSbOW9zw",
        "outputId": "0ff7ca70-4ed1-4f5a-9931-334a047cc124"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , 0.36419547, 0.        ,\n",
              "        0.        , 0.36419547, 0.        , 0.        , 0.26745392,\n",
              "        0.        , 0.36419547, 0.        , 0.        , 0.        ,\n",
              "        0.36419547, 0.36419547, 0.36419547, 0.        , 0.        ,\n",
              "        0.36419547, 0.        , 0.        , 0.        , 0.        ],\n",
              "       [0.39105193, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.39105193, 0.        , 0.        , 0.39105193, 0.28717648,\n",
              "        0.        , 0.        , 0.        , 0.39105193, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.39105193, 0.        , 0.        , 0.39105193],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.57735027,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.57735027, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.57735027, 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.4472136 , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.4472136 , 0.        , 0.4472136 ,\n",
              "        0.        , 0.        , 0.        , 0.4472136 , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.4472136 , 0.        ],\n",
              "       [0.        , 0.57735027, 0.57735027, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.57735027,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# initialize tf-idf vectorizer object\n",
        "vectorizer = TfidfVectorizer()"
      ],
      "metadata": {
        "id": "xwBCVQOkXBrn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute bag of word counts and tf-idf values\n",
        "X = vectorizer.fit_transform(corpus)"
      ],
      "metadata": {
        "id": "xzNoOmGjXGIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert sparse matrix to numpy array to view\n",
        "X.toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQekoAOVXLkR",
        "outputId": "d12289a1-f240-4826-c8e7-e46753382358"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.30298183, 0.        , 0.        , 0.30298183, 0.        ,\n",
              "        0.        , 0.20291046, 0.        , 0.24444384, 0.        ,\n",
              "        0.30298183, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.30298183, 0.30298183, 0.30298183, 0.        , 0.40582093,\n",
              "        0.        , 0.30298183, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.30298183, 0.        ],\n",
              "       [0.        , 0.30015782, 0.        , 0.60031564, 0.        ,\n",
              "        0.        , 0.        , 0.30015782, 0.        , 0.        ,\n",
              "        0.        , 0.20101919, 0.30015782, 0.24216544, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.30015782, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.30015782, 0.        , 0.        ,\n",
              "        0.30015782, 0.        , 0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.38077552, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.25500981, 0.        , 0.        , 0.38077552,\n",
              "        0.        , 0.38077552, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.25500981,\n",
              "        0.        , 0.        , 0.        , 0.38077552, 0.        ,\n",
              "        0.        , 0.        , 0.38077552, 0.        , 0.38077552],\n",
              "       [0.        , 0.        , 0.30101067, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.30101067,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.30101067, 0.        , 0.30101067,\n",
              "        0.        , 0.        , 0.        , 0.30101067, 0.60477106,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.30101067,\n",
              "        0.        , 0.30101067, 0.        , 0.        , 0.        ],\n",
              "       [0.5       , 0.        , 0.        , 0.        , 0.5       ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.5       , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.5       , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lJ82B1OVXPTJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}