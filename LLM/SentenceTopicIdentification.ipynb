{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oQKo3dHoKtCk"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.decomposition import NMF, LatentDirichletAllocation\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def display_topics(model, feature_names, no_top_words):\n",
        "    for topic_idx, topic in enumerate(model.components_):\n",
        "        print (\"Topic %d:\" % (topic_idx))\n",
        "        print (\" \".join([feature_names[i]\n",
        "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))"
      ],
      "metadata": {
        "id": "__mmDNAsK2PY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = fetch_20newsgroups(shuffle=True, random_state=1, remove=('headers', 'footers', 'quotes'))\n",
        "documents = dataset.data"
      ],
      "metadata": {
        "id": "qM7WBXtpLHtn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q10m5TW-EjSs",
        "outputId": "416d043d-4ee2-4ef4-d329-32ccfcb6f6d8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "with(open('/content/Walden.txt', 'r') as in_file):\n",
        "    text = in_file.read()\n",
        "    sents = nltk.sent_tokenize(text)\n",
        "\n",
        "documents = sents\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LYzenTNNXwl",
        "outputId": "8fc5d72f-2d38-40dd-c43c-f102e69e7857"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "no_features = 1000"
      ],
      "metadata": {
        "id": "OoKAciu4LM6n"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NMF is able to use tf-idf\n",
        "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, max_features=no_features, stop_words='english')\n",
        "tfidf = tfidf_vectorizer.fit_transform(documents)\n",
        "tfidf_feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "\n",
        "# LDA can only use raw term counts for LDA because it is a probabilistic graphical model\n",
        "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2, max_features=no_features, stop_words='english')\n",
        "tf = tf_vectorizer.fit_transform(documents)\n",
        "\n",
        "tfidf_feature_names = tfidf_vectorizer.get_feature_names_out()"
      ],
      "metadata": {
        "id": "nu6QiCm6LQy1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "no_topics = 10\n",
        "no_top_words = 5"
      ],
      "metadata": {
        "id": "ViaodV-tLk6Z"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run NMF\n",
        "nmf = NMF(n_components=no_topics, random_state=1, l1_ratio=.5, init='nndsvd').fit(tfidf)\n",
        "display_topics(nmf, tfidf_feature_names, no_top_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QA-2U95uLWvG",
        "outputId": "aa68a82b-29be-4df8-a0bc-e88137c261b3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 0:\n",
            "don just people think like\n",
            "Topic 1:\n",
            "card video monitor cards drivers\n",
            "Topic 2:\n",
            "god jesus bible believe christ\n",
            "Topic 3:\n",
            "game team year games season\n",
            "Topic 4:\n",
            "new car 00 10 sale\n",
            "Topic 5:\n",
            "thanks know does mail advance\n",
            "Topic 6:\n",
            "windows file use files window\n",
            "Topic 7:\n",
            "edu soon com university cs\n",
            "Topic 8:\n",
            "key chip encryption clipper keys\n",
            "Topic 9:\n",
            "drive scsi hard drives disk\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run LDA\n",
        "lda = LatentDirichletAllocation(max_iter=5, learning_method='online', learning_offset=50.,random_state=0).fit(tf)\n",
        "\n",
        "\n",
        "# display_topics(nmf, tfidf_feature_names, no_top_words)\n",
        "display_topics(lda, tfidf_feature_names, no_top_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7LgKzYGM_tv",
        "outputId": "b2a96656-f485-46e0-c338-fc1de8ab1a63"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 0:\n",
            "people gun armenian armenians war\n",
            "Topic 1:\n",
            "government people law mr use\n",
            "Topic 2:\n",
            "space program output entry data\n",
            "Topic 3:\n",
            "key car chip used keys\n",
            "Topic 4:\n",
            "edu file com available mail\n",
            "Topic 5:\n",
            "god people does jesus say\n",
            "Topic 6:\n",
            "windows use drive thanks does\n",
            "Topic 7:\n",
            "ax max b8f g9v a86\n",
            "Topic 8:\n",
            "just don like think know\n",
            "Topic 9:\n",
            "10 00 25 15 12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lmPqODeDFEev"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "source": [
        "def display_topics(model, feature_names, no_top_words, print_topics=False): # Add a flag to control printing\n",
        "    \"\"\"\n",
        "    Displays topics and their top features.\n",
        "\n",
        "    Args:\n",
        "        model: The trained topic model.\n",
        "        feature_names: List of feature names.\n",
        "        no_top_words: Number of top words to display per topic.\n",
        "        print_topics: Whether to print topics to console.\n",
        "\n",
        "    Returns:\n",
        "        List of tuples containing (topic_idx, top_features).\n",
        "    \"\"\"\n",
        "    topic_results = []\n",
        "    for topic_idx, topic in enumerate(model.components_):\n",
        "        topic_results.append((topic_idx,\n",
        "                             [feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
        "        if print_topics: # Print only if the flag is True\n",
        "            print(\"Topic %d:\" % (topic_idx))\n",
        "            print(\" \".join([feature_names[i]\n",
        "                            for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
        "\n",
        "    return topic_results\n",
        "\n",
        "\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "TNliRMBTGgnf"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_string = \"\"\n",
        "for topic_idx, top_features in display_topics(lda, tfidf_feature_names, 10):\n",
        "    output_string += f\"Topic {topic_idx}: {', '.join(top_features)}\\n\"\n",
        "\n",
        "print(output_string)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3nMzFeyGp20",
        "outputId": "d4b9ce5d-6a0c-49e6-e0c6-392cc2681d6f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 0: people, gun, armenian, armenians, war, turkish, states, israel, said, children\n",
            "Topic 1: government, people, law, mr, use, president, don, think, right, public\n",
            "Topic 2: space, program, output, entry, data, nasa, use, science, research, build\n",
            "Topic 3: key, car, chip, used, keys, bike, use, bit, clipper, number\n",
            "Topic 4: edu, file, com, available, mail, ftp, files, information, image, send\n",
            "Topic 5: god, people, does, jesus, say, think, believe, don, know, just\n",
            "Topic 6: windows, use, drive, thanks, does, problem, know, card, like, using\n",
            "Topic 7: ax, max, b8f, g9v, a86, pl, 145, 1d9, 0t, 34u\n",
            "Topic 8: just, don, like, think, know, good, time, ve, people, said\n",
            "Topic 9: 10, 00, 25, 15, 12, 20, 11, 14, 17, 16\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVbOVeCwFU4G",
        "outputId": "cf4f80ff-803c-4bd1-bc0f-514e5c8eee30"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}